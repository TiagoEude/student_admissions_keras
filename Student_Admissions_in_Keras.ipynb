{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Student_Admissions_in_Keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagoeude/Student_Admissions_in_Keras/blob/master/Student_Admissions_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FR-9gleVzlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a23a6a9f-0d5d-427d-f4bd-bf4dedb3b20a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras as kr\n",
        "data = pd.read_csv(\"student_data.csv\")\n",
        "print(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     admit  gre   gpa  rank\n",
            "0        0  380  3.61     3\n",
            "1        1  660  3.67     3\n",
            "2        1  800  4.00     1\n",
            "3        1  640  3.19     4\n",
            "4        0  520  2.93     4\n",
            "5        1  760  3.00     2\n",
            "6        1  560  2.98     1\n",
            "7        0  400  3.08     2\n",
            "8        1  540  3.39     3\n",
            "9        0  700  3.92     2\n",
            "10       0  800  4.00     4\n",
            "11       0  440  3.22     1\n",
            "12       1  760  4.00     1\n",
            "13       0  700  3.08     2\n",
            "14       1  700  4.00     1\n",
            "15       0  480  3.44     3\n",
            "16       0  780  3.87     4\n",
            "17       0  360  2.56     3\n",
            "18       0  800  3.75     2\n",
            "19       1  540  3.81     1\n",
            "20       0  500  3.17     3\n",
            "21       1  660  3.63     2\n",
            "22       0  600  2.82     4\n",
            "23       0  680  3.19     4\n",
            "24       1  760  3.35     2\n",
            "25       1  800  3.66     1\n",
            "26       1  620  3.61     1\n",
            "27       1  520  3.74     4\n",
            "28       1  780  3.22     2\n",
            "29       0  520  3.29     1\n",
            "..     ...  ...   ...   ...\n",
            "370      1  540  3.77     2\n",
            "371      1  680  3.76     3\n",
            "372      1  680  2.42     1\n",
            "373      1  620  3.37     1\n",
            "374      0  560  3.78     2\n",
            "375      0  560  3.49     4\n",
            "376      0  620  3.63     2\n",
            "377      1  800  4.00     2\n",
            "378      0  640  3.12     3\n",
            "379      0  540  2.70     2\n",
            "380      0  700  3.65     2\n",
            "381      1  540  3.49     2\n",
            "382      0  540  3.51     2\n",
            "383      0  660  4.00     1\n",
            "384      1  480  2.62     2\n",
            "385      0  420  3.02     1\n",
            "386      1  740  3.86     2\n",
            "387      0  580  3.36     2\n",
            "388      0  640  3.17     2\n",
            "389      0  640  3.51     2\n",
            "390      1  800  3.05     2\n",
            "391      1  660  3.88     2\n",
            "392      1  600  3.38     3\n",
            "393      1  620  3.75     2\n",
            "394      1  460  3.99     3\n",
            "395      0  620  4.00     2\n",
            "396      0  560  3.04     3\n",
            "397      0  460  2.63     2\n",
            "398      0  700  3.65     2\n",
            "399      0  600  3.89     3\n",
            "\n",
            "[400 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecLiPvhOXORb",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM6BVBxiWYOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " data[\"gre\"] = data[\"gre\"]/800\n",
        " data[\"gpa\"] = data[\"gpa\"]/4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hxQt_MCXSm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(data)[:,1:]\n",
        "y = kr.utils.to_categorical(np.array(data[\"admit\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuov5RkVYaVZ",
        "colab_type": "text"
      },
      "source": [
        "## Building the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apOV1yvxYACB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=3))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbr4mx6DYgdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d02e6d24-603a-4041-dc05-45346aa4d239"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               896       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 5,090\n",
            "Trainable params: 5,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2dBIwaawzf",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "719m7VeBagZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "a0e7d970-8e2b-44a7-f754-adec6507d9a5"
      },
      "source": [
        "model.fit(X, y, nb_epoch=1000, batch_size=100, verbose=0)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f95a70e5c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqUFnjrxcIXE",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAS0AmYsbL5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6d250f1-bc9b-49ba-97f9-a97d0b3d676c"
      },
      "source": [
        "score = model.evaluate(X, y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400/400 [==============================] - 0s 143us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbycU3r1cQr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dd1385f-c061-47c4-ef55-f8c35fecfb47"
      },
      "source": [
        "# Scoring the model\n",
        "score = model.evaluate(X, y)\n",
        "print(\"\\nAccuracy: \", score[-1])\n",
        "\n",
        "# Checking the predictions\n",
        "print(\"\\nPredictions:\")\n",
        "print(model.predict_proba(X))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400/400 [==============================] - 0s 43us/step\n",
            "\n",
            "Accuracy:  0.7075\n",
            "\n",
            "Predictions:\n",
            "[[0.2408492  0.05210817]\n",
            " [0.16711831 0.07599384]\n",
            " [0.06858146 0.17813623]\n",
            " [0.2536795  0.04931605]\n",
            " [0.3050878  0.04023549]\n",
            " [0.13284796 0.09536979]\n",
            " [0.13091692 0.09707174]\n",
            " [0.21003994 0.06007737]\n",
            " [0.21085405 0.0599032 ]\n",
            " [0.10841674 0.11617643]\n",
            " [0.16946185 0.07498148]\n",
            " [0.14367756 0.08860719]\n",
            " [0.07225657 0.16997615]\n",
            " [0.14075753 0.09012952]\n",
            " [0.07825309 0.15811813]\n",
            " [0.22377056 0.05630019]\n",
            " [0.18014821 0.07049805]\n",
            " [0.3170553  0.03832048]\n",
            " [0.09960225 0.12583038]\n",
            " [0.10346812 0.12191793]\n",
            " [0.23482081 0.0534552 ]\n",
            " [0.12539905 0.10099834]\n",
            " [0.28872156 0.04277232]\n",
            " [0.24270564 0.05170047]\n",
            " [0.11914423 0.10605395]\n",
            " [0.0758706  0.16259655]\n",
            " [0.09852493 0.12766102]\n",
            " [0.25287157 0.04958346]\n",
            " [0.12068284 0.1047267 ]\n",
            " [0.12553018 0.10118777]\n",
            " [0.24491388 0.0513131 ]\n",
            " [0.16105348 0.07878175]\n",
            " [0.1951156  0.06490391]\n",
            " [0.12573227 0.10055858]\n",
            " [0.16470778 0.07726532]\n",
            " [0.2118403  0.05953726]\n",
            " [0.11680317 0.10849673]\n",
            " [0.24617058 0.05078095]\n",
            " [0.18176869 0.06977057]\n",
            " [0.26036167 0.0477609 ]\n",
            " [0.20684764 0.06093195]\n",
            " [0.1540964  0.08244926]\n",
            " [0.15795907 0.08040562]\n",
            " [0.2262285  0.05563238]\n",
            " [0.14697593 0.08633912]\n",
            " [0.22859001 0.05505136]\n",
            " [0.14760873 0.0860731 ]\n",
            " [0.3083861  0.03975683]\n",
            " [0.3596114  0.03322276]\n",
            " [0.2516977  0.04965791]\n",
            " [0.1622447  0.07831517]\n",
            " [0.31564918 0.03874564]\n",
            " [0.21637747 0.05836326]\n",
            " [0.13641849 0.09297994]\n",
            " [0.183907   0.06893378]\n",
            " [0.13626438 0.09302679]\n",
            " [0.21734837 0.05799979]\n",
            " [0.28472978 0.04332536]\n",
            " [0.17781532 0.07144937]\n",
            " [0.28872156 0.04277232]\n",
            " [0.15230659 0.08338615]\n",
            " [0.2679994  0.0464991 ]\n",
            " [0.17153311 0.07403216]\n",
            " [0.15436435 0.08228195]\n",
            " [0.16844773 0.07546371]\n",
            " [0.13794765 0.09203213]\n",
            " [0.20249403 0.06255072]\n",
            " [0.10866117 0.11629406]\n",
            " [0.1015999  0.12402198]\n",
            " [0.07429326 0.16573304]\n",
            " [0.15567169 0.0816308 ]\n",
            " [0.37228417 0.03192794]\n",
            " [0.2865699  0.04321864]\n",
            " [0.12485811 0.10149419]\n",
            " [0.21690997 0.05823049]\n",
            " [0.13995874 0.09063306]\n",
            " [0.20742494 0.0609265 ]\n",
            " [0.12573227 0.10055858]\n",
            " [0.12880784 0.09864905]\n",
            " [0.08723363 0.14308974]\n",
            " [0.2550274  0.04898524]\n",
            " [0.15752381 0.0806123 ]\n",
            " [0.20551428 0.0613955 ]\n",
            " [0.34865957 0.03451347]\n",
            " [0.20904163 0.0604836 ]\n",
            " [0.18507764 0.06846768]\n",
            " [0.14994076 0.0847199 ]\n",
            " [0.14272434 0.0889841 ]\n",
            " [0.09776393 0.12855023]\n",
            " [0.11176255 0.11288103]\n",
            " [0.11148971 0.11311141]\n",
            " [0.08502033 0.14648637]\n",
            " [0.09511101 0.13141602]\n",
            " [0.17346385 0.07313302]\n",
            " [0.13302979 0.09532797]\n",
            " [0.13764805 0.09217772]\n",
            " [0.23363337 0.05389026]\n",
            " [0.16357782 0.07771817]\n",
            " [0.14971566 0.08476153]\n",
            " [0.2542769  0.04910758]\n",
            " [0.28262663 0.04371616]\n",
            " [0.19070372 0.06647646]\n",
            " [0.3202604  0.03813952]\n",
            " [0.18053785 0.07036385]\n",
            " [0.11351329 0.11121014]\n",
            " [0.13783616 0.0919846 ]\n",
            " [0.08957177 0.13956377]\n",
            " [0.18663535 0.0679093 ]\n",
            " [0.27936578 0.04424751]\n",
            " [0.16962808 0.07490537]\n",
            " [0.24942493 0.05019772]\n",
            " [0.30294275 0.04062828]\n",
            " [0.28672743 0.0429987 ]\n",
            " [0.11464071 0.11046231]\n",
            " [0.14682135 0.08644661]\n",
            " [0.1603081  0.07928538]\n",
            " [0.1789571  0.07094824]\n",
            " [0.11536905 0.1094549 ]\n",
            " [0.07496426 0.16438472]\n",
            " [0.29830903 0.04112166]\n",
            " [0.14703533 0.08645967]\n",
            " [0.21322903 0.05906481]\n",
            " [0.24936163 0.05007407]\n",
            " [0.24676648 0.05066296]\n",
            " [0.1450777  0.08747566]\n",
            " [0.2698789  0.04615706]\n",
            " [0.10358199 0.1217514 ]\n",
            " [0.19604883 0.06468117]\n",
            " [0.16924444 0.07502759]\n",
            " [0.3083244  0.03979251]\n",
            " [0.15277457 0.08313012]\n",
            " [0.16694239 0.07599592]\n",
            " [0.15035903 0.08450153]\n",
            " [0.2404398  0.05210975]\n",
            " [0.17709264 0.07161495]\n",
            " [0.21077973 0.05995968]\n",
            " [0.26736373 0.04662085]\n",
            " [0.14374608 0.0882971 ]\n",
            " [0.14232635 0.08921349]\n",
            " [0.10228178 0.12322354]\n",
            " [0.11742768 0.10765609]\n",
            " [0.21801385 0.05793801]\n",
            " [0.21448451 0.0590134 ]\n",
            " [0.20008081 0.06324807]\n",
            " [0.25731546 0.04860452]\n",
            " [0.25230604 0.0495424 ]\n",
            " [0.17220208 0.07376435]\n",
            " [0.24689129 0.05058929]\n",
            " [0.1497753  0.084968  ]\n",
            " [0.09162742 0.13661107]\n",
            " [0.07407129 0.16618389]\n",
            " [0.19259953 0.06579334]\n",
            " [0.11706284 0.10797971]\n",
            " [0.19673479 0.06436726]\n",
            " [0.1750235  0.07255054]\n",
            " [0.29196522 0.04225162]\n",
            " [0.2009804  0.06280515]\n",
            " [0.12113479 0.10479724]\n",
            " [0.13097945 0.09679189]\n",
            " [0.15167463 0.08371717]\n",
            " [0.15892619 0.07991245]\n",
            " [0.13423193 0.09450611]\n",
            " [0.12125942 0.10431242]\n",
            " [0.1991426  0.06344444]\n",
            " [0.15504318 0.08194381]\n",
            " [0.07825309 0.15811813]\n",
            " [0.30829436 0.03981024]\n",
            " [0.1499176  0.08467379]\n",
            " [0.18679756 0.06798309]\n",
            " [0.18326148 0.06923792]\n",
            " [0.24151248 0.05193776]\n",
            " [0.24621207 0.05075637]\n",
            " [0.17211214 0.0737417 ]\n",
            " [0.10997459 0.11451805]\n",
            " [0.2717347  0.04583892]\n",
            " [0.14365175 0.08839661]\n",
            " [0.20556334 0.06136447]\n",
            " [0.19960088 0.06337139]\n",
            " [0.19405553 0.06525362]\n",
            " [0.30444133 0.04020041]\n",
            " [0.17049834 0.07450685]\n",
            " [0.24975666 0.05027097]\n",
            " [0.10576022 0.11895603]\n",
            " [0.13868868 0.09159917]\n",
            " [0.32044157 0.03803805]\n",
            " [0.10432735 0.1204246 ]\n",
            " [0.19339088 0.06553954]\n",
            " [0.17608398 0.07201907]\n",
            " [0.1708279  0.07430238]\n",
            " [0.17018175 0.07464036]\n",
            " [0.15950674 0.07958516]\n",
            " [0.14437023 0.08782008]\n",
            " [0.16708064 0.07603022]\n",
            " [0.3028865  0.04066405]\n",
            " [0.14316607 0.08871174]\n",
            " [0.1457594  0.08717793]\n",
            " [0.19856778 0.06367967]\n",
            " [0.32096156 0.03803006]\n",
            " [0.18273565 0.06944224]\n",
            " [0.23472962 0.05367255]\n",
            " [0.15460727 0.08203584]\n",
            " [0.15985265 0.07946217]\n",
            " [0.07825309 0.15811813]\n",
            " [0.26970783 0.04628065]\n",
            " [0.09279343 0.1350843 ]\n",
            " [0.13716039 0.09238988]\n",
            " [0.08532152 0.14599633]\n",
            " [0.09521893 0.13182586]\n",
            " [0.22448939 0.05605912]\n",
            " [0.14580008 0.08713627]\n",
            " [0.21808365 0.05788285]\n",
            " [0.16882566 0.07518348]\n",
            " [0.2066018  0.06108609]\n",
            " [0.18651897 0.06795967]\n",
            " [0.13923562 0.09119138]\n",
            " [0.20763436 0.06077665]\n",
            " [0.18221283 0.06966409]\n",
            " [0.12225732 0.10387447]\n",
            " [0.15067169 0.08447477]\n",
            " [0.1457594  0.08717793]\n",
            " [0.21730855 0.05802771]\n",
            " [0.14806804 0.08576438]\n",
            " [0.14467728 0.08796686]\n",
            " [0.14742038 0.08601919]\n",
            " [0.12968579 0.09761679]\n",
            " [0.16239876 0.07816339]\n",
            " [0.1346077  0.09426409]\n",
            " [0.2932138  0.04207653]\n",
            " [0.17065397 0.0744468 ]\n",
            " [0.12320438 0.10269606]\n",
            " [0.26422703 0.04721451]\n",
            " [0.20180857 0.06266624]\n",
            " [0.19768187 0.06404704]\n",
            " [0.2909264  0.04225713]\n",
            " [0.07891086 0.15686288]\n",
            " [0.1584886  0.08011788]\n",
            " [0.13097945 0.09679189]\n",
            " [0.1433801  0.08868513]\n",
            " [0.31574172 0.03869373]\n",
            " [0.16916567 0.07502562]\n",
            " [0.2186166  0.0575482 ]\n",
            " [0.10641906 0.11870554]\n",
            " [0.19973025 0.06327638]\n",
            " [0.15044704 0.08441773]\n",
            " [0.13212234 0.09621343]\n",
            " [0.12918925 0.09794128]\n",
            " [0.13348728 0.09498963]\n",
            " [0.19437954 0.06513405]\n",
            " [0.16424036 0.0773187 ]\n",
            " [0.16855434 0.07535815]\n",
            " [0.24085534 0.05214447]\n",
            " [0.25800538 0.04843128]\n",
            " [0.13567674 0.0936206 ]\n",
            " [0.2591302  0.04826432]\n",
            " [0.20797464 0.06083572]\n",
            " [0.18812421 0.06736255]\n",
            " [0.1681818  0.07552686]\n",
            " [0.16220927 0.07835183]\n",
            " [0.15778631 0.08056265]\n",
            " [0.12189648 0.10383555]\n",
            " [0.14334476 0.08853287]\n",
            " [0.1955171  0.06473896]\n",
            " [0.22809294 0.05513084]\n",
            " [0.16220927 0.07835183]\n",
            " [0.187365   0.06775302]\n",
            " [0.25813353 0.04831862]\n",
            " [0.27310732 0.0455392 ]\n",
            " [0.18221098 0.06964716]\n",
            " [0.12860122 0.09852621]\n",
            " [0.2577119  0.04831615]\n",
            " [0.11669916 0.1083042 ]\n",
            " [0.21435943 0.05887166]\n",
            " [0.12046605 0.10499564]\n",
            " [0.10208264 0.12341335]\n",
            " [0.17753032 0.0714668 ]\n",
            " [0.16633964 0.07630923]\n",
            " [0.20955044 0.06036386]\n",
            " [0.10519254 0.11998674]\n",
            " [0.25436985 0.0491389 ]\n",
            " [0.14597651 0.08696249]\n",
            " [0.11386684 0.11087835]\n",
            " [0.26860747 0.04625744]\n",
            " [0.23247996 0.0541586 ]\n",
            " [0.29383978 0.04198921]\n",
            " [0.1821819  0.06965703]\n",
            " [0.2573475  0.04858217]\n",
            " [0.08677396 0.1436938 ]\n",
            " [0.21794814 0.05799231]\n",
            " [0.21366337 0.05908796]\n",
            " [0.38057774 0.03101331]\n",
            " [0.14014211 0.09059069]\n",
            " [0.13461038 0.094107  ]\n",
            " [0.11934632 0.10594907]\n",
            " [0.06918791 0.1767351 ]\n",
            " [0.16756594 0.07583368]\n",
            " [0.22444996 0.05608594]\n",
            " [0.12363788 0.1026727 ]\n",
            " [0.19499129 0.06490496]\n",
            " [0.15401179 0.0825291 ]\n",
            " [0.16723862 0.07588151]\n",
            " [0.14281079 0.08889601]\n",
            " [0.17057383 0.07443559]\n",
            " [0.20587811 0.06135949]\n",
            " [0.10939425 0.11520156]\n",
            " [0.34205636 0.03512347]\n",
            " [0.25358152 0.04938456]\n",
            " [0.12677729 0.10019892]\n",
            " [0.14535111 0.08740404]\n",
            " [0.17233151 0.07365751]\n",
            " [0.26413447 0.04706684]\n",
            " [0.17289516 0.07351559]\n",
            " [0.12384775 0.10222921]\n",
            " [0.1622814  0.07827801]\n",
            " [0.2584744  0.04841381]\n",
            " [0.2647967  0.04713371]\n",
            " [0.25356463 0.04910463]\n",
            " [0.231513   0.05419105]\n",
            " [0.19242486 0.06589821]\n",
            " [0.26597515 0.04695028]\n",
            " [0.12241995 0.10368341]\n",
            " [0.2479634  0.0504275 ]\n",
            " [0.16755185 0.07586637]\n",
            " [0.30572143 0.04015362]\n",
            " [0.22852618 0.05489457]\n",
            " [0.25905597 0.04802594]\n",
            " [0.08288372 0.14999512]\n",
            " [0.13473618 0.09412357]\n",
            " [0.15077975 0.08428311]\n",
            " [0.15315452 0.08295774]\n",
            " [0.31105632 0.03936562]\n",
            " [0.13626438 0.09302679]\n",
            " [0.17107216 0.07421562]\n",
            " [0.16029993 0.07938114]\n",
            " [0.2034271  0.06218043]\n",
            " [0.21716082 0.05813667]\n",
            " [0.09547973 0.13149917]\n",
            " [0.2305407  0.05450481]\n",
            " [0.26555857 0.04692388]\n",
            " [0.12557405 0.10113904]\n",
            " [0.17714283 0.07162896]\n",
            " [0.2911805  0.04243612]\n",
            " [0.25072873 0.04974625]\n",
            " [0.24546754 0.05122125]\n",
            " [0.16679665 0.07611361]\n",
            " [0.21845669 0.05772159]\n",
            " [0.24359238 0.05138013]\n",
            " [0.14856333 0.08550429]\n",
            " [0.13286844 0.09551156]\n",
            " [0.19372967 0.06539401]\n",
            " [0.1684131  0.0753375 ]\n",
            " [0.09478295 0.13185886]\n",
            " [0.18862122 0.06719765]\n",
            " [0.21620613 0.05830723]\n",
            " [0.12277862 0.10305938]\n",
            " [0.14128816 0.08993298]\n",
            " [0.10427079 0.12088105]\n",
            " [0.1327056  0.09552199]\n",
            " [0.0941959  0.13312382]\n",
            " [0.1890454  0.06709641]\n",
            " [0.14249736 0.08904114]\n",
            " [0.10022086 0.12567851]\n",
            " [0.11451337 0.1106222 ]\n",
            " [0.14202195 0.08935133]\n",
            " [0.17476612 0.07267553]\n",
            " [0.11601999 0.1092197 ]\n",
            " [0.26553088 0.04676425]\n",
            " [0.26154798 0.04756606]\n",
            " [0.17809248 0.07127622]\n",
            " [0.09218183 0.1359356 ]\n",
            " [0.09540334 0.1310381 ]\n",
            " [0.14172581 0.08965796]\n",
            " [0.15853351 0.08011702]\n",
            " [0.13206396 0.09615541]\n",
            " [0.10627803 0.11878985]\n",
            " [0.13744268 0.09240076]\n",
            " [0.2572842  0.04862672]\n",
            " [0.1325342  0.09571281]\n",
            " [0.09224257 0.13523844]\n",
            " [0.20076528 0.06297106]\n",
            " [0.19574827 0.06457928]\n",
            " [0.11790958 0.10717937]\n",
            " [0.15448436 0.08227581]\n",
            " [0.15354055 0.08278304]\n",
            " [0.08259603 0.15048724]\n",
            " [0.21626437 0.05818447]\n",
            " [0.15732923 0.08089983]\n",
            " [0.10453153 0.12025118]\n",
            " [0.15221766 0.08346924]\n",
            " [0.148653   0.08541843]\n",
            " [0.13381591 0.09479499]\n",
            " [0.12377384 0.10216779]\n",
            " [0.11601192 0.10890508]\n",
            " [0.1962201  0.06452486]\n",
            " [0.12768179 0.09927171]\n",
            " [0.19707856 0.06435749]\n",
            " [0.11812466 0.10706022]\n",
            " [0.22634757 0.05555239]\n",
            " [0.22112814 0.05683577]\n",
            " [0.11790958 0.10717937]\n",
            " [0.16946995 0.07498401]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVPOsq82cWpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}